nohup: ignoring input
Finetuning starting.
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards:  50%|█████     | 1/2 [01:02<01:02, 62.33s/it]Downloading shards: 100%|██████████| 2/2 [01:39<00:00, 47.54s/it]Downloading shards: 100%|██████████| 2/2 [01:39<00:00, 49.76s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
trainable params: 10,644,480 || all params: 6,901,373,952 || trainable%: 0.1542
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 7876 examples [00:00, 12960.74 examples/s]Generating train split: 7876 examples [00:00, 12877.77 examples/s]
Generating valid split: 0 examples [00:00, ? examples/s]Generating valid split: 1000 examples [00:00, 19633.13 examples/s]
Map:   0%|          | 0/7876 [00:00<?, ? examples/s]Map:  13%|█▎        | 1000/7876 [00:00<00:05, 1204.62 examples/s]Map:  25%|██▌       | 2000/7876 [00:01<00:04, 1251.13 examples/s]Map:  38%|███▊      | 3000/7876 [00:02<00:03, 1272.77 examples/s]Map:  51%|█████     | 4000/7876 [00:03<00:03, 1290.77 examples/s]Map:  63%|██████▎   | 5000/7876 [00:03<00:02, 1306.70 examples/s]Map:  76%|███████▌  | 6000/7876 [00:04<00:01, 1318.79 examples/s]Map:  89%|████████▉ | 7000/7876 [00:05<00:00, 1334.87 examples/s]Map: 100%|██████████| 7876/7876 [00:06<00:00, 1330.40 examples/s]Map: 100%|██████████| 7876/7876 [00:06<00:00, 1304.28 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1361.42 examples/s]Map: 100%|██████████| 1000/1000 [00:00<00:00, 1329.66 examples/s]
[2024-09-07 20:01:49,811] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
df: /root/.triton/autotune: No such file or directory
/workspace/venv/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/workspace/venv/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/workspace/venv/lib/python3.10/site-packages/transformers/trainer.py:3108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)
wandb: Currently logged in as: tcwong. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.7
wandb: Run data is saved locally in /workspace/wandb/run-20240907_200206-vff5tzyv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deepseek_prover_sft_no_err-random-09-07-09-00
wandb: ⭐️ View project at https://wandb.ai/tcwong/decoder
wandb: 🚀 View run at https://wandb.ai/tcwong/decoder/runs/vff5tzyv
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
  0%|          | 0/492 [00:00<?, ?it/s]/workspace/venv/lib/python3.10/site-packages/transformers/trainer.py:2843: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
W0907 20:02:21.272000 140026108764608 torch/_dynamo/variables/tensor.py:715] [17/0] Graph break from `Tensor.item()`, consider setting:
W0907 20:02:21.272000 140026108764608 torch/_dynamo/variables/tensor.py:715] [17/0]     torch._dynamo.config.capture_scalar_outputs = True
W0907 20:02:21.272000 140026108764608 torch/_dynamo/variables/tensor.py:715] [17/0] or:
W0907 20:02:21.272000 140026108764608 torch/_dynamo/variables/tensor.py:715] [17/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1
W0907 20:02:21.272000 140026108764608 torch/_dynamo/variables/tensor.py:715] [17/0] to include these operations in the captured graph.
W0907 20:02:21.272000 140026108764608 torch/_dynamo/variables/tensor.py:715] [17/0] 
The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.
/workspace/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 61%|██████    | 301/492 [02:29<01:34,  2.01it/s] 61%|██████▏   | 302/492 [04:24<03:16,  1.04s/it] 62%|██████▏   | 303/492 [06:19<05:40,  1.80s/it] 62%|██████▏   | 304/492 [08:14<09:00,  2.87s/it] 62%|██████▏   | 305/492 [10:08<13:36,  4.37s/it]                                                  62%|██████▏   | 305/492 [10:08<13:36,  4.37s/it] 62%|██████▏   | 306/492 [12:03<19:56,  6.44s/it] 62%|██████▏   | 307/492 [13:58<28:35,  9.27s/it] 63%|██████▎   | 308/492 [15:54<40:06, 13.08s/it] 63%|██████▎   | 309/492 [17:48<55:00, 18.03s/it] 63%|██████▎   | 310/492 [19:43<1:13:52, 24.35s/it]                                                    63%|██████▎   | 310/492 [19:43<1:13:52, 24.35s/it] 63%|██████▎   | 311/492 [21:38<1:36:42, 32.06s/it] 63%|██████▎   | 312/492 [23:33<2:03:17, 41.10s/it] 64%|██████▎   | 313/492 [25:28<2:32:02, 50.97s/it] 64%|██████▍   | 314/492 [27:23<3:01:50, 61.29s/it] 64%|██████▍   | 315/492 [29:18<3:30:18, 71.29s/it]                                                    64%|██████▍   | 315/492 [29:18<3:30:18, 71.29s/it] 64%|██████▍   | 316/492 [31:13<3:56:02, 80.47s/it] 64%|██████▍   | 317/492 [33:08<4:17:52, 88.42s/it] 65%|██████▍   | 318/492 [35:02<4:35:05, 94.86s/it] 65%|██████▍   | 319/492 [36:56<4:48:17, 99.99s/it] 65%|██████▌   | 320/492 [38:52<4:58:33, 104.15s/it]                                                     65%|██████▌   | 320/492 [38:52<4:58:33, 104.15s/it] 65%|██████▌   | 321/492 [40:47<5:05:27, 107.18s/it] 65%|██████▌   | 322/492 [42:42<5:10:02, 109.43s/it] 66%|██████▌   | 323/492 [44:37<5:12:51, 111.07s/it] 66%|██████▌   | 324/492 [46:32<5:14:33, 112.34s/it] 66%|██████▌   | 325/492 [48:27<5:15:03, 113.19s/it]                                                     66%|██████▌   | 325/492 [48:27<5:15:03, 113.19s/it] 66%|██████▋   | 326/492 [50:23<5:14:56, 113.84s/it] 66%|██████▋   | 327/492 [52:17<5:13:38, 114.05s/it] 67%|██████▋   | 328/492 [54:13<5:13:12, 114.59s/it] 67%|██████▋   | 329/492 [56:08<5:11:22, 114.61s/it] 67%|██████▋   | 330/492 [58:03<5:09:30, 114.63s/it]                                                     67%|██████▋   | 330/492 [58:03<5:09:30, 114.63s/it] 67%|██████▋   | 331/492 [59:58<5:07:57, 114.77s/it] 67%|██████▋   | 332/492 [1:01:52<5:05:58, 114.74s/it] 68%|██████▊   | 333/492 [1:03:47<5:03:58, 114.71s/it] 68%|██████▊   | 334/492 [1:05:42<5:02:02, 114.70s/it] 68%|██████▊   | 335/492 [1:07:37<5:00:49, 114.96s/it]                                                       68%|██████▊   | 335/492 [1:07:37<5:00:49, 114.96s/it] 68%|██████▊   | 336/492 [1:09:32<4:59:00, 115.00s/it] 68%|██████▊   | 337/492 [1:11:28<4:57:15, 115.07s/it] 69%|██████▊   | 338/492 [1:13:23<4:55:14, 115.03s/it] 69%|██████▉   | 339/492 [1:15:17<4:53:12, 114.98s/it] 69%|██████▉   | 340/492 [1:17:13<4:51:31, 115.08s/it]                                                       69%|██████▉   | 340/492 [1:17:13<4:51:31, 115.08s/it] 69%|██████▉   | 341/492 [1:19:07<4:49:17, 114.95s/it] 70%|██████▉   | 342/492 [1:21:02<4:47:15, 114.90s/it] 70%|██████▉   | 343/492 [1:22:56<4:44:52, 114.71s/it] 70%|██████▉   | 344/492 [1:24:52<4:43:20, 114.87s/it] 70%|███████   | 345/492 [1:26:47<4:41:44, 115.00s/it]                                                       70%|███████   | 345/492 [1:26:47<4:41:44, 115.00s/it] 70%|███████   | 346/492 [1:28:42<4:39:54, 115.03s/it] 71%|███████   | 347/492 [1:30:36<4:37:34, 114.86s/it] 71%|███████   | 348/492 [1:32:31<4:35:34, 114.83s/it] 71%|███████   | 349/492 [1:34:26<4:33:55, 114.93s/it] 71%|███████   | 350/492 [1:36:22<4:32:17, 115.05s/it]                                                       71%|███████   | 350/492 [1:36:22<4:32:17, 115.05s/it]{'loss': 0.0855, 'grad_norm': 0.05062380060553551, 'learning_rate': 3.803421678562213e-05, 'epoch': 2.48}
{'loss': 0.0866, 'grad_norm': 0.06058161333203316, 'learning_rate': 3.631685049639586e-05, 'epoch': 2.52}
{'loss': 0.0836, 'grad_norm': 0.05282078683376312, 'learning_rate': 3.461676388250651e-05, 'epoch': 2.56}
{'loss': 0.0777, 'grad_norm': 0.06284045428037643, 'learning_rate': 3.293610388715048e-05, 'epoch': 2.6}
{'loss': 0.095, 'grad_norm': 0.06628148257732391, 'learning_rate': 3.127699292074683e-05, 'epoch': 2.64}
{'loss': 0.0851, 'grad_norm': 0.0586889423429966, 'learning_rate': 2.964152618066508e-05, 'epoch': 2.68}
{'loss': 0.0876, 'grad_norm': 0.06476856768131256, 'learning_rate': 2.8031769005319147e-05, 'epoch': 2.72}
{'loss': 0.0836, 'grad_norm': 0.062451042234897614, 'learning_rate': 2.6449754265968264e-05, 'epoch': 2.76}
{'loss': 0.0795, 'grad_norm': 0.09133639186620712, 'learning_rate': 2.4897479799518796e-05, 'epoch': 2.8}
{'loss': 0.0843, 'grad_norm': 0.06529180705547333, 'learning_rate': 2.3376905885569182e-05, 'epoch': 2.84}

  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|▏         | 2/125 [00:04<04:20,  2.12s/it][A
  2%|▏         | 3/125 [00:08<06:27,  3.18s/it][A
  3%|▎         | 4/125 [00:13<07:29,  3.71s/it][A
  4%|▍         | 5/125 [00:18<08:06,  4.05s/it][A
  5%|▍         | 6/125 [00:22<08:24,  4.24s/it][A
  6%|▌         | 7/125 [00:27<08:36,  4.37s/it][A
  6%|▋         | 8/125 [00:32<08:40,  4.45s/it][A
  7%|▋         | 9/125 [00:36<08:41,  4.49s/it][A
  8%|▊         | 10/125 [00:41<08:42,  4.54s/it][A
  9%|▉         | 11/125 [00:46<08:42,  4.58s/it][A
 10%|▉         | 12/125 [00:50<08:38,  4.59s/it][A
 10%|█         | 13/125 [00:55<08:33,  4.59s/it][A
 11%|█         | 14/125 [00:59<08:31,  4.60s/it][A
 12%|█▏        | 15/125 [01:04<08:25,  4.60s/it][A
 13%|█▎        | 16/125 [01:09<08:22,  4.61s/it][A
 14%|█▎        | 17/125 [01:13<08:19,  4.62s/it][A
 14%|█▍        | 18/125 [01:18<08:15,  4.63s/it][A
 15%|█▌        | 19/125 [01:22<08:09,  4.61s/it][A
 16%|█▌        | 20/125 [01:27<08:05,  4.62s/it][A
 17%|█▋        | 21/125 [01:32<08:00,  4.62s/it][A
 18%|█▊        | 22/125 [01:36<07:54,  4.61s/it][A
 18%|█▊        | 23/125 [01:41<07:49,  4.60s/it][A
 19%|█▉        | 24/125 [01:46<07:47,  4.62s/it][A
 20%|██        | 25/125 [01:50<07:45,  4.66s/it][A
 21%|██        | 26/125 [01:55<07:42,  4.67s/it][A
 22%|██▏       | 27/125 [02:00<07:36,  4.65s/it][A
 22%|██▏       | 28/125 [02:04<07:28,  4.63s/it][A
 23%|██▎       | 29/125 [02:09<07:24,  4.63s/it][A
 24%|██▍       | 30/125 [02:13<07:18,  4.61s/it][A
 25%|██▍       | 31/125 [02:18<07:14,  4.62s/it][A
 26%|██▌       | 32/125 [02:23<07:09,  4.62s/it][A
 26%|██▋       | 33/125 [02:27<07:04,  4.62s/it][A
 27%|██▋       | 34/125 [02:32<06:59,  4.61s/it][A
 28%|██▊       | 35/125 [02:36<06:54,  4.61s/it][A
 29%|██▉       | 36/125 [02:41<06:50,  4.62s/it][A
 30%|██▉       | 37/125 [02:46<06:45,  4.60s/it][A
 30%|███       | 38/125 [02:50<06:40,  4.61s/it][A
 31%|███       | 39/125 [02:55<06:36,  4.62s/it][A
 32%|███▏      | 40/125 [02:59<06:32,  4.62s/it][A
 33%|███▎      | 41/125 [03:04<06:30,  4.64s/it][A
 34%|███▎      | 42/125 [03:09<06:24,  4.63s/it][A
 34%|███▍      | 43/125 [03:13<06:19,  4.63s/it][A
 35%|███▌      | 44/125 [03:18<06:14,  4.63s/it][A
 36%|███▌      | 45/125 [03:23<06:11,  4.65s/it][A
 37%|███▋      | 46/125 [03:27<06:06,  4.63s/it][A
 38%|███▊      | 47/125 [03:32<05:59,  4.61s/it][A
 38%|███▊      | 48/125 [03:37<05:55,  4.62s/it][A
 39%|███▉      | 49/125 [03:41<05:51,  4.62s/it][A
 40%|████      | 50/125 [03:46<05:46,  4.63s/it][A
 41%|████      | 51/125 [03:50<05:42,  4.62s/it][A
 42%|████▏     | 52/125 [03:55<05:37,  4.62s/it][A
 42%|████▏     | 53/125 [04:00<05:32,  4.62s/it][A
 43%|████▎     | 54/125 [04:04<05:28,  4.63s/it][A
 44%|████▍     | 55/125 [04:09<05:24,  4.64s/it][A
 45%|████▍     | 56/125 [04:14<05:19,  4.63s/it][A
 46%|████▌     | 57/125 [04:18<05:14,  4.63s/it][A
 46%|████▋     | 58/125 [04:23<05:11,  4.65s/it][A
 47%|████▋     | 59/125 [04:27<05:05,  4.62s/it][A
 48%|████▊     | 60/125 [04:32<05:00,  4.63s/it][A
 49%|████▉     | 61/125 [04:37<04:55,  4.61s/it][A
 50%|████▉     | 62/125 [04:41<04:50,  4.61s/it][A
 50%|█████     | 63/125 [04:46<04:47,  4.63s/it][A
 51%|█████     | 64/125 [04:51<04:42,  4.64s/it][A
 52%|█████▏    | 65/125 [04:55<04:37,  4.62s/it][A
 53%|█████▎    | 66/125 [05:00<04:33,  4.64s/it][A
 54%|█████▎    | 67/125 [05:04<04:27,  4.62s/it][A
 54%|█████▍    | 68/125 [05:09<04:23,  4.63s/it][A
 55%|█████▌    | 69/125 [05:14<04:18,  4.62s/it][A
 56%|█████▌    | 70/125 [05:18<04:14,  4.63s/it][A
 57%|█████▋    | 71/125 [05:23<04:10,  4.63s/it][A
 58%|█████▊    | 72/125 [05:28<04:06,  4.64s/it][A
 58%|█████▊    | 73/125 [05:32<04:01,  4.65s/it][A
 59%|█████▉    | 74/125 [05:37<03:59,  4.69s/it][A
 60%|██████    | 75/125 [05:42<03:53,  4.67s/it][A
 61%|██████    | 76/125 [05:46<03:48,  4.66s/it][A
 62%|██████▏   | 77/125 [05:51<03:43,  4.65s/it][A
 62%|██████▏   | 78/125 [05:56<03:38,  4.64s/it][A
 63%|██████▎   | 79/125 [06:00<03:32,  4.62s/it][A
 64%|██████▍   | 80/125 [06:05<03:28,  4.62s/it][A
 65%|██████▍   | 81/125 [06:09<03:23,  4.63s/it][A
 66%|██████▌   | 82/125 [06:14<03:18,  4.62s/it][A
 66%|██████▋   | 83/125 [06:19<03:13,  4.62s/it][A
 67%|██████▋   | 84/125 [06:23<03:09,  4.62s/it][A
 68%|██████▊   | 85/125 [06:28<03:05,  4.63s/it][A
 69%|██████▉   | 86/125 [06:33<03:00,  4.63s/it][A
 70%|██████▉   | 87/125 [06:37<02:56,  4.63s/it][A
 70%|███████   | 88/125 [06:42<02:51,  4.63s/it][A
 71%|███████   | 89/125 [06:46<02:46,  4.63s/it][A
 72%|███████▏  | 90/125 [06:51<02:41,  4.62s/it][A
 73%|███████▎  | 91/125 [06:56<02:36,  4.60s/it][A
 74%|███████▎  | 92/125 [07:00<02:31,  4.59s/it][A
 74%|███████▍  | 93/125 [07:05<02:27,  4.62s/it][A
 75%|███████▌  | 94/125 [07:09<02:23,  4.62s/it][A
 76%|███████▌  | 95/125 [07:14<02:18,  4.62s/it][A
 77%|███████▋  | 96/125 [07:19<02:13,  4.62s/it][A
 78%|███████▊  | 97/125 [07:23<02:09,  4.62s/it][A
 78%|███████▊  | 98/125 [07:28<02:04,  4.62s/it][A
 79%|███████▉  | 99/125 [07:33<01:59,  4.61s/it][A
 80%|████████  | 100/125 [07:37<01:55,  4.62s/it][A
 81%|████████  | 101/125 [07:42<01:50,  4.62s/it][A
 82%|████████▏ | 102/125 [07:46<01:46,  4.63s/it][A
 82%|████████▏ | 103/125 [07:51<01:42,  4.65s/it][A
 83%|████████▎ | 104/125 [07:56<01:37,  4.65s/it][A
 84%|████████▍ | 105/125 [08:00<01:32,  4.63s/it][A
 85%|████████▍ | 106/125 [08:05<01:27,  4.62s/it][A
 86%|████████▌ | 107/125 [08:10<01:23,  4.61s/it][A
 86%|████████▋ | 108/125 [08:14<01:18,  4.62s/it][A
 87%|████████▋ | 109/125 [08:19<01:13,  4.62s/it][A
 88%|████████▊ | 110/125 [08:23<01:09,  4.62s/it][A
 89%|████████▉ | 111/125 [08:28<01:04,  4.63s/it][A
 90%|████████▉ | 112/125 [08:33<01:00,  4.62s/it][A
 90%|█████████ | 113/125 [08:37<00:55,  4.61s/it][A
 91%|█████████ | 114/125 [08:42<00:50,  4.63s/it][A
 92%|█████████▏| 115/125 [08:47<00:46,  4.65s/it][A
 93%|█████████▎| 116/125 [08:51<00:41,  4.64s/it][A
 94%|█████████▎| 117/125 [08:56<00:37,  4.65s/it][A
 94%|█████████▍| 118/125 [09:01<00:32,  4.64s/it][A
 95%|█████████▌| 119/125 [09:05<00:27,  4.63s/it][A
 96%|█████████▌| 120/125 [09:10<00:23,  4.63s/it][A
 97%|█████████▋| 121/125 [09:14<00:18,  4.63s/it][A
 98%|█████████▊| 122/125 [09:19<00:13,  4.63s/it][A
 98%|█████████▊| 123/125 [09:24<00:09,  4.65s/it][A
 99%|█████████▉| 124/125 [09:28<00:04,  4.65s/it][A
100%|██████████| 125/125 [09:33<00:00,  4.64s/it][A                                                      
                                                 [A 71%|███████   | 350/492 [1:46:01<4:32:17, 115.05s/it]
100%|██████████| 125/125 [09:33<00:00,  4.64s/it][A
                                                 [A/workspace/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
wandb: Adding directory to artifact (./model_training/deepseek_prover_sft_no_err/checkpoints-random-09-07-09-00/checkpoint-350)... Done. 4.7s
/workspace/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 71%|███████▏  | 351/492 [1:48:07<11:26:20, 292.06s/it] 72%|███████▏  | 352/492 [1:50:02<9:17:32, 238.95s/it]  72%|███████▏  | 353/492 [1:51:56<7:47:08, 201.64s/it] 72%|███████▏  | 354/492 [1:53:52<6:44:08, 175.72s/it] 72%|███████▏  | 355/492 [1:55:46<5:59:26, 157.42s/it]                                                       72%|███████▏  | 355/492 [1:55:46<5:59:26, 157.42s/it] 72%|███████▏  | 356/492 [1:57:41<5:28:01, 144.72s/it] 73%|███████▎  | 357/492 [1:59:37<5:05:39, 135.85s/it] 73%|███████▎  | 358/492 [2:01:32<4:49:26, 129.60s/it] 73%|███████▎  | 359/492 [2:03:27<4:37:43, 125.29s/it] 73%|███████▎  | 360/492 [2:05:22<4:28:50, 122.20s/it]                                                       73%|███████▎  | 360/492 [2:05:22<4:28:50, 122.20s/it] 73%|███████▎  | 361/492 [2:07:17<4:22:11, 120.09s/it] 74%|███████▎  | 362/492 [2:09:12<4:16:40, 118.47s/it] 74%|███████▍  | 363/492 [2:11:07<4:12:32, 117.46s/it] 74%|███████▍  | 364/492 [2:13:02<4:09:02, 116.74s/it] 74%|███████▍  | 365/492 [2:14:57<4:05:48, 116.13s/it]                                                       74%|███████▍  | 365/492 [2:14:57<4:05:48, 116.13s/it] 74%|███████▍  | 366/492 [2:16:52<4:03:07, 115.77s/it] 75%|███████▍  | 367/492 [2:18:46<4:00:39, 115.52s/it] 75%|███████▍  | 368/492 [2:20:42<3:58:33, 115.43s/it] 75%|███████▌  | 369/492 [2:22:37<3:56:38, 115.43s/it]/workspace/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 75%|███████▌  | 370/492 [2:24:36<3:56:43, 116.42s/it]                                                       75%|███████▌  | 370/492 [2:24:36<3:56:43, 116.42s/it] 75%|███████▌  | 371/492 [2:26:30<3:53:24, 115.74s/it] 76%|███████▌  | 372/492 [2:28:25<3:51:00, 115.50s/it] 76%|███████▌  | 373/492 [2:30:20<3:49:00, 115.47s/it] 76%|███████▌  | 374/492 [2:32:15<3:46:45, 115.30s/it] 76%|███████▌  | 375/492 [2:34:10<3:44:36, 115.18s/it]                                                       76%|███████▌  | 375/492 [2:34:10<3:44:36, 115.18s/it] 76%|███████▋  | 376/492 [2:36:05<3:42:37, 115.15s/it] 77%|███████▋  | 377/492 [2:38:00<3:40:20, 114.96s/it] 77%|███████▋  | 378/492 [2:39:54<3:38:12, 114.85s/it] 77%|███████▋  | 379/492 [2:41:50<3:36:30, 114.96s/it] 77%|███████▋  | 380/492 [2:43:44<3:34:33, 114.94s/it]                                                       77%|███████▋  | 380/492 [2:43:44<3:34:33, 114.94s/it] 77%|███████▋  | 381/492 [2:45:40<3:32:42, 114.97s/it] 78%|███████▊  | 382/492 [2:47:34<3:30:36, 114.88s/it] 78%|███████▊  | 383/492 [2:49:29<3:28:23, 114.72s/it] 78%|███████▊  | 384/492 [2:51:23<3:26:31, 114.74s/it] 78%|███████▊  | 385/492 [2:53:18<3:24:36, 114.73s/it]                                                       78%|███████▊  | 385/492 [2:53:18<3:24:36, 114.73s/it] 78%|███████▊  | 386/492 [2:55:13<3:22:41, 114.73s/it] 79%|███████▊  | 387/492 [2:57:08<3:21:04, 114.90s/it] 79%|███████▉  | 388/492 [2:59:03<3:19:08, 114.89s/it] 79%|███████▉  | 389/492 [3:00:57<3:17:03, 114.79s/it] 79%|███████▉  | 390/492 [3:02:53<3:15:24, 114.95s/it]                                                       79%|███████▉  | 390/492 [3:02:53<3:15:24, 114.95s/it] 79%|███████▉  | 391/492 [3:04:48<3:13:31, 114.97s/it] 80%|███████▉  | 392/492 [3:06:43<3:11:37, 114.97s/it] 80%|███████▉  | 393/492 [3:08:38<3:09:37, 114.92s/it] 80%|████████  | 394/492 [3:10:32<3:07:41, 114.91s/it] 80%|████████  | 395/492 [3:12:28<3:05:56, 115.01s/it]                                                       80%|████████  | 395/492 [3:12:28<3:05:56, 115.01s/it] 80%|████████  | 396/492 [3:14:23<3:03:54, 114.95s/it] 81%|████████  | 397/492 [3:16:18<3:02:02, 114.97s/it] 81%|████████  | 398/492 [3:18:12<2:59:57, 114.86s/it] 81%|████████  | 399/492 [3:20:08<2:58:17, 115.02s/it] 81%|████████▏ | 400/492 [3:22:02<2:56:08, 114.88s/it]                                                       81%|████████▏ | 400/492 [3:22:02<2:56:08, 114.88s/it]{'eval_loss': 0.0914108008146286, 'eval_runtime': 578.8025, 'eval_samples_per_second': 1.728, 'eval_steps_per_second': 0.216, 'epoch': 2.84}
{'loss': 0.0806, 'grad_norm': 0.05800933018326759, 'learning_rate': 2.1889952770883643e-05, 'epoch': 2.89}
{'loss': 0.086, 'grad_norm': 0.06730043888092041, 'learning_rate': 2.043849824442124e-05, 'epoch': 2.93}
{'loss': 0.0846, 'grad_norm': 0.05438319221138954, 'learning_rate': 1.9024375265982384e-05, 'epoch': 2.97}
{'loss': 0.0811, 'grad_norm': 0.06161397323012352, 'learning_rate': 1.764936965146773e-05, 'epoch': 3.01}
{'loss': 0.0736, 'grad_norm': 0.0842302069067955, 'learning_rate': 1.631521781767214e-05, 'epoch': 3.05}
{'loss': 0.0801, 'grad_norm': 0.06074338033795357, 'learning_rate': 1.502360458946232e-05, 'epoch': 3.09}
{'loss': 0.0805, 'grad_norm': 0.06264619529247284, 'learning_rate': 1.3776161072106702e-05, 'epoch': 3.13}
{'loss': 0.0841, 'grad_norm': 0.07572674006223679, 'learning_rate': 1.257446259144494e-05, 'epoch': 3.17}
{'loss': 0.0835, 'grad_norm': 0.08485180884599686, 'learning_rate': 1.1420026704498077e-05, 'epoch': 3.21}
{'loss': 0.0775, 'grad_norm': 0.05600133538246155, 'learning_rate': 1.031431128303153e-05, 'epoch': 3.25}

  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|▏         | 2/125 [00:04<04:44,  2.31s/it][A
  2%|▏         | 3/125 [00:09<06:41,  3.29s/it][A
  3%|▎         | 4/125 [00:13<07:37,  3.78s/it][A
  4%|▍         | 5/125 [00:18<08:11,  4.10s/it][A
  5%|▍         | 6/125 [00:23<08:28,  4.28s/it][A
  6%|▌         | 7/125 [00:27<08:38,  4.40s/it][A
  6%|▋         | 8/125 [00:32<08:42,  4.47s/it][A
  7%|▋         | 9/125 [00:37<08:42,  4.50s/it][A
  8%|▊         | 10/125 [00:41<08:43,  4.55s/it][A
  9%|▉         | 11/125 [00:46<08:42,  4.59s/it][A
 10%|▉         | 12/125 [00:51<08:38,  4.59s/it][A
 10%|█         | 13/125 [00:55<08:34,  4.59s/it][A
 11%|█         | 14/125 [01:00<08:31,  4.61s/it][A
 12%|█▏        | 15/125 [01:04<08:25,  4.60s/it][A
 13%|█▎        | 16/125 [01:09<08:22,  4.61s/it][A
 14%|█▎        | 17/125 [01:14<08:19,  4.62s/it][A
 14%|█▍        | 18/125 [01:18<08:15,  4.63s/it][A
 15%|█▌        | 19/125 [01:23<08:09,  4.61s/it][A
 16%|█▌        | 20/125 [01:27<08:05,  4.62s/it][A
 17%|█▋        | 21/125 [01:32<08:00,  4.62s/it][A
 18%|█▊        | 22/125 [01:37<07:54,  4.61s/it][A
 18%|█▊        | 23/125 [01:41<07:49,  4.60s/it][A
 19%|█▉        | 24/125 [01:46<07:47,  4.62s/it][A
 20%|██        | 25/125 [01:51<07:45,  4.65s/it][A
 21%|██        | 26/125 [01:55<07:42,  4.67s/it][A
 22%|██▏       | 27/125 [02:00<07:35,  4.65s/it][A
 22%|██▏       | 28/125 [02:05<07:28,  4.63s/it][A
 23%|██▎       | 29/125 [02:09<07:24,  4.63s/it][A
 24%|██▍       | 30/125 [02:14<07:18,  4.61s/it][A
 25%|██▍       | 31/125 [02:18<07:14,  4.62s/it][A
 26%|██▌       | 32/125 [02:23<07:09,  4.62s/it][A
 26%|██▋       | 33/125 [02:28<07:04,  4.62s/it][A
 27%|██▋       | 34/125 [02:32<06:59,  4.61s/it][A
 28%|██▊       | 35/125 [02:37<06:54,  4.61s/it][A
 29%|██▉       | 36/125 [02:41<06:50,  4.62s/it][A
 30%|██▉       | 37/125 [02:46<06:45,  4.60s/it][A
 30%|███       | 38/125 [02:51<06:40,  4.61s/it][A
 31%|███       | 39/125 [02:55<06:36,  4.62s/it][A
 32%|███▏      | 40/125 [03:00<06:32,  4.62s/it][A
 33%|███▎      | 41/125 [03:05<06:29,  4.64s/it][A
 34%|███▎      | 42/125 [03:09<06:24,  4.63s/it][A
 34%|███▍      | 43/125 [03:14<06:19,  4.63s/it][A
 35%|███▌      | 44/125 [03:18<06:14,  4.63s/it][A
 36%|███▌      | 45/125 [03:23<06:11,  4.65s/it][A
 37%|███▋      | 46/125 [03:28<06:06,  4.63s/it][A
 38%|███▊      | 47/125 [03:32<05:59,  4.61s/it][A
 38%|███▊      | 48/125 [03:37<05:55,  4.62s/it][A
 39%|███▉      | 49/125 [03:42<05:51,  4.62s/it][A
 40%|████      | 50/125 [03:46<05:46,  4.63s/it][A
 41%|████      | 51/125 [03:51<05:42,  4.62s/it][A
 42%|████▏     | 52/125 [03:55<05:37,  4.62s/it][A
 42%|████▏     | 53/125 [04:00<05:32,  4.62s/it][A
 43%|████▎     | 54/125 [04:05<05:28,  4.63s/it][A
 44%|████▍     | 55/125 [04:09<05:24,  4.64s/it][A
 45%|████▍     | 56/125 [04:14<05:19,  4.63s/it][A
 46%|████▌     | 57/125 [04:19<05:14,  4.63s/it][A
 46%|████▋     | 58/125 [04:23<05:11,  4.65s/it][A
 47%|████▋     | 59/125 [04:28<05:04,  4.62s/it][A
 48%|████▊     | 60/125 [04:32<05:00,  4.63s/it][A
 49%|████▉     | 61/125 [04:37<04:55,  4.61s/it][A
 50%|████▉     | 62/125 [04:42<04:50,  4.61s/it][A
 50%|█████     | 63/125 [04:46<04:47,  4.63s/it][A
 51%|█████     | 64/125 [04:51<04:42,  4.64s/it][A
 52%|█████▏    | 65/125 [04:56<04:36,  4.62s/it][A
 53%|█████▎    | 66/125 [05:00<04:33,  4.64s/it][A
 54%|█████▎    | 67/125 [05:05<04:27,  4.62s/it][A
 54%|█████▍    | 68/125 [05:09<04:23,  4.62s/it][A
 55%|█████▌    | 69/125 [05:14<04:18,  4.62s/it][A
 56%|█████▌    | 70/125 [05:19<04:14,  4.63s/it][A
 57%|█████▋    | 71/125 [05:23<04:10,  4.63s/it][A
 58%|█████▊    | 72/125 [05:28<04:06,  4.64s/it][A
 58%|█████▊    | 73/125 [05:33<04:01,  4.65s/it][A
 59%|█████▉    | 74/125 [05:37<03:59,  4.69s/it][A
 60%|██████    | 75/125 [05:42<03:53,  4.66s/it][A
 61%|██████    | 76/125 [05:47<03:48,  4.66s/it][A
 62%|██████▏   | 77/125 [05:51<03:43,  4.65s/it][A
 62%|██████▏   | 78/125 [05:56<03:38,  4.64s/it][A
 63%|██████▎   | 79/125 [06:01<03:32,  4.62s/it][A
 64%|██████▍   | 80/125 [06:05<03:28,  4.63s/it][A
 65%|██████▍   | 81/125 [06:10<03:23,  4.63s/it][A
 66%|██████▌   | 82/125 [06:14<03:18,  4.62s/it][A
 66%|██████▋   | 83/125 [06:19<03:14,  4.62s/it][A
 67%|██████▋   | 84/125 [06:24<03:09,  4.62s/it][A
 68%|██████▊   | 85/125 [06:28<03:05,  4.63s/it][A
 69%|██████▉   | 86/125 [06:33<03:00,  4.63s/it][A
 70%|██████▉   | 87/125 [06:38<02:56,  4.63s/it][A
 70%|███████   | 88/125 [06:42<02:51,  4.63s/it][A
 71%|███████   | 89/125 [06:47<02:46,  4.63s/it][A
 72%|███████▏  | 90/125 [06:51<02:41,  4.61s/it][A
 73%|███████▎  | 91/125 [06:56<02:36,  4.60s/it][A
 74%|███████▎  | 92/125 [07:01<02:31,  4.59s/it][A
 74%|███████▍  | 93/125 [07:05<02:27,  4.62s/it][A
 75%|███████▌  | 94/125 [07:10<02:22,  4.61s/it][A
 76%|███████▌  | 95/125 [07:14<02:18,  4.62s/it][A
 77%|███████▋  | 96/125 [07:19<02:13,  4.62s/it][A
 78%|███████▊  | 97/125 [07:24<02:09,  4.62s/it][A
 78%|███████▊  | 98/125 [07:28<02:04,  4.62s/it][A
 79%|███████▉  | 99/125 [07:33<01:59,  4.61s/it][A
 80%|████████  | 100/125 [07:38<01:55,  4.62s/it][A
 81%|████████  | 101/125 [07:42<01:50,  4.62s/it][A
 82%|████████▏ | 102/125 [07:47<01:46,  4.63s/it][A
 82%|████████▏ | 103/125 [07:52<01:42,  4.65s/it][A
 83%|████████▎ | 104/125 [07:56<01:37,  4.64s/it][A
 84%|████████▍ | 105/125 [08:01<01:32,  4.63s/it][A
 85%|████████▍ | 106/125 [08:05<01:27,  4.62s/it][A
 86%|████████▌ | 107/125 [08:10<01:22,  4.61s/it][A
 86%|████████▋ | 108/125 [08:15<01:18,  4.62s/it][A
 87%|████████▋ | 109/125 [08:19<01:13,  4.62s/it][A
 88%|████████▊ | 110/125 [08:24<01:09,  4.62s/it][A
 89%|████████▉ | 111/125 [08:28<01:04,  4.63s/it][A
 90%|████████▉ | 112/125 [08:33<01:00,  4.62s/it][A
 90%|█████████ | 113/125 [08:38<00:55,  4.60s/it][A
 91%|█████████ | 114/125 [08:42<00:50,  4.63s/it][A
 92%|█████████▏| 115/125 [08:47<00:46,  4.65s/it][A
 93%|█████████▎| 116/125 [08:52<00:41,  4.64s/it][A
 94%|█████████▎| 117/125 [08:56<00:37,  4.65s/it][A
 94%|█████████▍| 118/125 [09:01<00:32,  4.64s/it][A
 95%|█████████▌| 119/125 [09:06<00:27,  4.63s/it][A
 96%|█████████▌| 120/125 [09:10<00:23,  4.63s/it][A
 97%|█████████▋| 121/125 [09:15<00:18,  4.63s/it][A
 98%|█████████▊| 122/125 [09:19<00:13,  4.63s/it][A
 98%|█████████▊| 123/125 [09:24<00:09,  4.65s/it][A
 99%|█████████▉| 124/125 [09:29<00:04,  4.65s/it][A
100%|██████████| 125/125 [09:33<00:00,  4.64s/it][A                                                      
                                                 [A 81%|████████▏ | 400/492 [3:31:41<2:56:08, 114.88s/it]
100%|██████████| 125/125 [09:34<00:00,  4.64s/it][A
                                                 [A/workspace/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
wandb: Adding directory to artifact (./model_training/deepseek_prover_sft_no_err/checkpoints-random-09-07-09-00/checkpoint-400)... Done. 4.6s
/workspace/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 82%|████████▏ | 401/492 [3:33:47<7:22:35, 291.81s/it] 82%|████████▏ | 402/492 [3:35:42<5:58:10, 238.79s/it] 82%|████████▏ | 403/492 [3:37:37<4:59:13, 201.72s/it] 82%|████████▏ | 404/492 [3:39:32<4:17:38, 175.66s/it] 82%|████████▏ | 405/492 [3:41:27<3:48:13, 157.39s/it]                                                       82%|████████▏ | 405/492 [3:41:27<3:48:13, 157.39s/it] 83%|████████▎ | 406/492 [3:43:22<3:27:28, 144.74s/it] 83%|████████▎ | 407/492 [3:45:17<3:12:20, 135.77s/it] 83%|████████▎ | 408/492 [3:47:12<3:01:17, 129.49s/it] 83%|████████▎ | 409/492 [3:49:07<2:53:10, 125.18s/it] 83%|████████▎ | 410/492 [3:51:02<2:46:52, 122.11s/it]                                                       83%|████████▎ | 410/492 [3:51:02<2:46:52, 122.11s/it] 84%|████████▎ | 411/492 [3:52:56<2:41:53, 119.92s/it] 84%|████████▎ | 412/492 [3:54:51<2:37:52, 118.41s/it] 84%|████████▍ | 413/492 [3:56:46<2:34:31, 117.36s/it] 84%|████████▍ | 414/492 [3:58:42<2:31:46, 116.75s/it] 84%|████████▍ | 415/492 [4:00:37<2:29:12, 116.26s/it]                                                       84%|████████▍ | 415/492 [4:00:37<2:29:12, 116.26s/it] 85%|████████▍ | 416/492 [4:02:32<2:26:50, 115.93s/it] 85%|████████▍ | 417/492 [4:04:27<2:24:39, 115.73s/it] 85%|████████▍ | 418/492 [4:06:22<2:22:19, 115.39s/it] 85%|████████▌ | 419/492 [4:08:17<2:20:18, 115.33s/it] 85%|████████▌ | 420/492 [4:10:11<2:18:07, 115.10s/it]                                                       85%|████████▌ | 420/492 [4:10:11<2:18:07, 115.10s/it] 86%|████████▌ | 421/492 [4:12:06<2:16:01, 114.96s/it] 86%|████████▌ | 422/492 [4:14:00<2:13:54, 114.78s/it] 86%|████████▌ | 423/492 [4:15:55<2:11:54, 114.70s/it] 86%|████████▌ | 424/492 [4:17:49<2:09:51, 114.57s/it] 86%|████████▋ | 425/492 [4:19:44<2:08:03, 114.68s/it]                                                       86%|████████▋ | 425/492 [4:19:44<2:08:03, 114.68s/it] 87%|████████▋ | 426/492 [4:21:39<2:06:12, 114.73s/it] 87%|████████▋ | 427/492 [4:23:34<2:04:29, 114.91s/it] 87%|████████▋ | 428/492 [4:25:29<2:02:30, 114.85s/it] 87%|████████▋ | 429/492 [4:27:23<2:00:21, 114.63s/it] 87%|████████▋ | 430/492 [4:29:17<1:58:19, 114.51s/it]                                                       87%|████████▋ | 430/492 [4:29:17<1:58:19, 114.51s/it] 88%|████████▊ | 431/492 [4:31:12<1:56:27, 114.55s/it] 88%|████████▊ | 432/492 [4:33:07<1:54:41, 114.69s/it] 88%|████████▊ | 433/492 [4:35:02<1:52:55, 114.84s/it] 88%|████████▊ | 434/492 [4:36:57<1:50:56, 114.77s/it] 88%|████████▊ | 435/492 [4:38:52<1:49:04, 114.82s/it]                                                       88%|████████▊ | 435/492 [4:38:52<1:49:04, 114.82s/it] 89%|████████▊ | 436/492 [4:40:46<1:47:03, 114.71s/it] 89%|████████▉ | 437/492 [4:42:41<1:45:15, 114.82s/it] 89%|████████▉ | 438/492 [4:44:36<1:43:21, 114.84s/it] 89%|████████▉ | 439/492 [4:46:31<1:41:31, 114.93s/it] 89%|████████▉ | 440/492 [4:48:26<1:39:31, 114.84s/it]                                                       89%|████████▉ | 440/492 [4:48:26<1:39:31, 114.84s/it] 90%|████████▉ | 441/492 [4:50:21<1:37:42, 114.96s/it] 90%|████████▉ | 442/492 [4:52:16<1:35:47, 114.95s/it] 90%|█████████ | 443/492 [4:54:11<1:33:51, 114.92s/it] 90%|█████████ | 444/492 [4:56:06<1:31:56, 114.94s/it] 90%|█████████ | 445/492 [4:58:01<1:29:56, 114.83s/it]                                                       90%|█████████ | 445/492 [4:58:01<1:29:56, 114.83s/it] 91%|█████████ | 446/492 [4:59:55<1:28:01, 114.82s/it] 91%|█████████ | 447/492 [5:01:50<1:26:07, 114.83s/it] 91%|█████████ | 448/492 [5:03:45<1:24:09, 114.77s/it] 91%|█████████▏| 449/492 [5:05:40<1:22:15, 114.79s/it] 91%|█████████▏| 450/492 [5:07:35<1:20:24, 114.87s/it]                                                       91%|█████████▏| 450/492 [5:07:35<1:20:24, 114.87s/it]{'eval_loss': 0.09013215452432632, 'eval_runtime': 578.5208, 'eval_samples_per_second': 1.729, 'eval_steps_per_second': 0.216, 'epoch': 3.25}
{'loss': 0.0855, 'grad_norm': 0.05972089618444443, 'learning_rate': 9.258712672491415e-06, 'epoch': 3.29}
{'loss': 0.083, 'grad_norm': 0.07054904848337173, 'learning_rate': 8.254563928638893e-06, 'epoch': 3.33}
{'loss': 0.0852, 'grad_norm': 0.06772007048130035, 'learning_rate': 7.3031331341093915e-06, 'epoch': 3.37}
{'loss': 0.083, 'grad_norm': 0.06778612732887268, 'learning_rate': 6.405621797022848e-06, 'epoch': 3.41}
{'loss': 0.0727, 'grad_norm': 0.06333562731742859, 'learning_rate': 5.563163333667099e-06, 'epoch': 3.45}
{'loss': 0.0756, 'grad_norm': 0.05736032873392105, 'learning_rate': 4.776821637170526e-06, 'epoch': 3.49}
{'loss': 0.0805, 'grad_norm': 0.0700037032365799, 'learning_rate': 4.047589733971646e-06, 'epoch': 3.54}
{'loss': 0.0813, 'grad_norm': 0.0645386204123497, 'learning_rate': 3.376388529782215e-06, 'epoch': 3.58}
{'loss': 0.0808, 'grad_norm': 0.05811276286840439, 'learning_rate': 2.7640656466274782e-06, 'epoch': 3.62}
{'loss': 0.0807, 'grad_norm': 0.06826285272836685, 'learning_rate': 2.2113943524323167e-06, 'epoch': 3.66}

  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|▏         | 2/125 [00:04<04:44,  2.31s/it][A
  2%|▏         | 3/125 [00:09<06:40,  3.28s/it][A
  3%|▎         | 4/125 [00:13<07:37,  3.78s/it][A
  4%|▍         | 5/125 [00:18<08:11,  4.09s/it][A
  5%|▍         | 6/125 [00:23<08:28,  4.27s/it][A
  6%|▌         | 7/125 [00:27<08:38,  4.39s/it][A
  6%|▋         | 8/125 [00:32<08:41,  4.46s/it][A
  7%|▋         | 9/125 [00:37<08:41,  4.50s/it][A
  8%|▊         | 10/125 [00:41<08:42,  4.55s/it][A
  9%|▉         | 11/125 [00:46<08:42,  4.58s/it][A
 10%|▉         | 12/125 [00:50<08:38,  4.59s/it][A
 10%|█         | 13/125 [00:55<08:33,  4.58s/it][A
 11%|█         | 14/125 [01:00<08:30,  4.60s/it][A
 12%|█▏        | 15/125 [01:04<08:25,  4.59s/it][A
 13%|█▎        | 16/125 [01:09<08:22,  4.61s/it][A
 14%|█▎        | 17/125 [01:14<08:18,  4.62s/it][A
 14%|█▍        | 18/125 [01:18<08:14,  4.62s/it][A
 15%|█▌        | 19/125 [01:23<08:08,  4.61s/it][A
 16%|█▌        | 20/125 [01:27<08:04,  4.62s/it][A
 17%|█▋        | 21/125 [01:32<07:59,  4.61s/it][A
 18%|█▊        | 22/125 [01:37<07:54,  4.60s/it][A
 18%|█▊        | 23/125 [01:41<07:48,  4.60s/it][A
 19%|█▉        | 24/125 [01:46<07:46,  4.62s/it][A
 20%|██        | 25/125 [01:51<07:44,  4.65s/it][A
 21%|██        | 26/125 [01:55<07:41,  4.66s/it][A
 22%|██▏       | 27/125 [02:00<07:35,  4.65s/it][A
 22%|██▏       | 28/125 [02:04<07:28,  4.62s/it][A
 23%|██▎       | 29/125 [02:09<07:23,  4.62s/it][A
 24%|██▍       | 30/125 [02:14<07:17,  4.61s/it][A
 25%|██▍       | 31/125 [02:18<07:14,  4.62s/it][A
 26%|██▌       | 32/125 [02:23<07:08,  4.61s/it][A
 26%|██▋       | 33/125 [02:27<07:04,  4.61s/it][A
 27%|██▋       | 34/125 [02:32<06:58,  4.60s/it][A
 28%|██▊       | 35/125 [02:37<06:54,  4.60s/it][A
 29%|██▉       | 36/125 [02:41<06:50,  4.61s/it][A
 30%|██▉       | 37/125 [02:46<06:44,  4.60s/it][A
 30%|███       | 38/125 [02:50<06:40,  4.60s/it][A
 31%|███       | 39/125 [02:55<06:36,  4.61s/it][A
 32%|███▏      | 40/125 [03:00<06:31,  4.61s/it][A
 33%|███▎      | 41/125 [03:04<06:29,  4.64s/it][A
 34%|███▎      | 42/125 [03:09<06:24,  4.63s/it][A
 34%|███▍      | 43/125 [03:14<06:18,  4.62s/it][A
 35%|███▌      | 44/125 [03:18<06:14,  4.62s/it][A
 36%|███▌      | 45/125 [03:23<06:11,  4.64s/it][A
 37%|███▋      | 46/125 [03:27<06:05,  4.63s/it][A
 38%|███▊      | 47/125 [03:32<05:59,  4.61s/it][A
 38%|███▊      | 48/125 [03:37<05:55,  4.62s/it][A
 39%|███▉      | 49/125 [03:41<05:50,  4.62s/it][A
 40%|████      | 50/125 [03:46<05:46,  4.62s/it][A
 41%|████      | 51/125 [03:51<05:41,  4.62s/it][A
 42%|████▏     | 52/125 [03:55<05:36,  4.62s/it][A
 42%|████▏     | 53/125 [04:00<05:32,  4.62s/it][A
 43%|████▎     | 54/125 [04:04<05:28,  4.62s/it][A
 44%|████▍     | 55/125 [04:09<05:24,  4.63s/it][A
 45%|████▍     | 56/125 [04:14<05:19,  4.63s/it][A
 46%|████▌     | 57/125 [04:18<05:14,  4.62s/it][A
 46%|████▋     | 58/125 [04:23<05:10,  4.64s/it][A
 47%|████▋     | 59/125 [04:28<05:04,  4.62s/it][A
 48%|████▊     | 60/125 [04:32<05:00,  4.62s/it][A
 49%|████▉     | 61/125 [04:37<04:54,  4.60s/it][A
 50%|████▉     | 62/125 [04:41<04:50,  4.60s/it][A
 50%|█████     | 63/125 [04:46<04:46,  4.63s/it][A
 51%|█████     | 64/125 [04:51<04:42,  4.63s/it][A
 52%|█████▏    | 65/125 [04:55<04:36,  4.61s/it][A
 53%|█████▎    | 66/125 [05:00<04:33,  4.63s/it][A
 54%|█████▎    | 67/125 [05:04<04:27,  4.61s/it][A
 54%|█████▍    | 68/125 [05:09<04:23,  4.62s/it][A
 55%|█████▌    | 69/125 [05:14<04:18,  4.61s/it][A
 56%|█████▌    | 70/125 [05:18<04:14,  4.62s/it][A
 57%|█████▋    | 71/125 [05:23<04:09,  4.63s/it][A
 58%|█████▊    | 72/125 [05:28<04:05,  4.64s/it][A
 58%|█████▊    | 73/125 [05:32<04:01,  4.64s/it][A
 59%|█████▉    | 74/125 [05:37<03:58,  4.68s/it][A
 60%|██████    | 75/125 [05:42<03:53,  4.66s/it][A
 61%|██████    | 76/125 [05:46<03:47,  4.65s/it][A
 62%|██████▏   | 77/125 [05:51<03:42,  4.64s/it][A
 62%|██████▏   | 78/125 [05:56<03:37,  4.63s/it][A
 63%|██████▎   | 79/125 [06:00<03:32,  4.61s/it][A
 64%|██████▍   | 80/125 [06:05<03:27,  4.62s/it][A
 65%|██████▍   | 81/125 [06:09<03:23,  4.62s/it][A
 66%|██████▌   | 82/125 [06:14<03:18,  4.62s/it][A
 66%|██████▋   | 83/125 [06:19<03:13,  4.61s/it][A
 67%|██████▋   | 84/125 [06:23<03:09,  4.61s/it][A
 68%|██████▊   | 85/125 [06:28<03:04,  4.62s/it][A
 69%|██████▉   | 86/125 [06:32<03:00,  4.62s/it][A
 70%|██████▉   | 87/125 [06:37<02:55,  4.63s/it][A
 70%|███████   | 88/125 [06:42<02:51,  4.63s/it][A
 71%|███████   | 89/125 [06:46<02:46,  4.62s/it][A
 72%|███████▏  | 90/125 [06:51<02:41,  4.61s/it][A
 73%|███████▎  | 91/125 [06:55<02:36,  4.60s/it][A
 74%|███████▎  | 92/125 [07:00<02:31,  4.59s/it][A
 74%|███████▍  | 93/125 [07:05<02:27,  4.62s/it][A
 75%|███████▌  | 94/125 [07:09<02:22,  4.61s/it][A
 76%|███████▌  | 95/125 [07:14<02:18,  4.62s/it][A
 77%|███████▋  | 96/125 [07:19<02:13,  4.61s/it][A
 78%|███████▊  | 97/125 [07:23<02:09,  4.62s/it][A
 78%|███████▊  | 98/125 [07:28<02:04,  4.61s/it][A
 79%|███████▉  | 99/125 [07:32<01:59,  4.60s/it][A
 80%|████████  | 100/125 [07:37<01:55,  4.61s/it][A
 81%|████████  | 101/125 [07:42<01:50,  4.61s/it][A
 82%|████████▏ | 102/125 [07:46<01:46,  4.63s/it][A
 82%|████████▏ | 103/125 [07:51<01:42,  4.65s/it][A
 83%|████████▎ | 104/125 [07:56<01:37,  4.64s/it][A
 84%|████████▍ | 105/125 [08:00<01:32,  4.63s/it][A
 85%|████████▍ | 106/125 [08:05<01:27,  4.62s/it][A
 86%|████████▌ | 107/125 [08:09<01:22,  4.60s/it][A
 86%|████████▋ | 108/125 [08:14<01:18,  4.61s/it][A
 87%|████████▋ | 109/125 [08:19<01:13,  4.61s/it][A
 88%|████████▊ | 110/125 [08:23<01:09,  4.61s/it][A
 89%|████████▉ | 111/125 [08:28<01:04,  4.62s/it][A
 90%|████████▉ | 112/125 [08:32<00:59,  4.61s/it][A
 90%|█████████ | 113/125 [08:37<00:55,  4.60s/it][A
 91%|█████████ | 114/125 [08:42<00:50,  4.62s/it][A
 92%|█████████▏| 115/125 [08:46<00:46,  4.64s/it][A
 93%|█████████▎| 116/125 [08:51<00:41,  4.64s/it][A
 94%|█████████▎| 117/125 [08:56<00:37,  4.64s/it][A
 94%|█████████▍| 118/125 [09:00<00:32,  4.63s/it][A
 95%|█████████▌| 119/125 [09:05<00:27,  4.63s/it][A
 96%|█████████▌| 120/125 [09:09<00:23,  4.62s/it][A
 97%|█████████▋| 121/125 [09:14<00:18,  4.63s/it][A
 98%|█████████▊| 122/125 [09:19<00:13,  4.63s/it][A
 98%|█████████▊| 123/125 [09:23<00:09,  4.65s/it][A
 99%|█████████▉| 124/125 [09:28<00:04,  4.65s/it][A
100%|██████████| 125/125 [09:33<00:00,  4.64s/it][A                                                      
                                                 [A 91%|█████████▏| 450/492 [5:17:13<1:20:24, 114.87s/it]
100%|██████████| 125/125 [09:33<00:00,  4.64s/it][A
                                                 [A/workspace/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
wandb: Adding directory to artifact (./model_training/deepseek_prover_sft_no_err/checkpoints-random-09-07-09-00/checkpoint-450)... Done. 4.7s
/workspace/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 92%|█████████▏| 451/492 [5:19:18<3:19:07, 291.39s/it] 92%|█████████▏| 452/492 [5:21:12<2:38:52, 238.32s/it] 92%|█████████▏| 453/492 [5:23:07<2:10:48, 201.24s/it] 92%|█████████▏| 454/492 [5:25:02<1:50:59, 175.26s/it] 92%|█████████▏| 455/492 [5:26:57<1:36:56, 157.21s/it]                                                       92%|█████████▏| 455/492 [5:26:57<1:36:56, 157.21s/it] 93%|█████████▎| 456/492 [5:28:52<1:26:41, 144.49s/it] 93%|█████████▎| 457/492 [5:30:47<1:19:09, 135.70s/it] 93%|█████████▎| 458/492 [5:32:42<1:13:25, 129.57s/it] 93%|█████████▎| 459/492 [5:34:37<1:08:48, 125.11s/it] 93%|█████████▎| 460/492 [5:36:32<1:05:02, 121.96s/it]                                                       93%|█████████▎| 460/492 [5:36:32<1:05:02, 121.96s/it] 94%|█████████▎| 461/492 [5:38:26<1:01:52, 119.75s/it] 94%|█████████▍| 462/492 [5:40:20<59:02, 118.10s/it]   94%|█████████▍| 463/492 [5:42:15<56:37, 117.14s/it] 94%|█████████▍| 464/492 [5:44:10<54:20, 116.46s/it] 95%|█████████▍| 465/492 [5:46:05<52:13, 116.04s/it]                                                     95%|█████████▍| 465/492 [5:46:05<52:13, 116.04s/it] 95%|█████████▍| 466/492 [5:48:01<50:12, 115.87s/it] 95%|█████████▍| 467/492 [5:49:56<48:14, 115.78s/it] 95%|█████████▌| 468/492 [5:51:51<46:10, 115.43s/it] 95%|█████████▌| 469/492 [5:53:46<44:10, 115.26s/it] 96%|█████████▌| 470/492 [5:55:40<42:10, 115.04s/it]                                                     96%|█████████▌| 470/492 [5:55:40<42:10, 115.04s/it] 96%|█████████▌| 471/492 [5:57:35<40:12, 114.90s/it] 96%|█████████▌| 472/492 [5:59:30<38:21, 115.05s/it] 96%|█████████▌| 473/492 [6:01:25<36:22, 114.87s/it] 96%|█████████▋| 474/492 [6:03:20<34:28, 114.89s/it] 97%|█████████▋| 475/492 [6:05:15<32:34, 114.94s/it]                                                     97%|█████████▋| 475/492 [6:05:15<32:34, 114.94s/it] 97%|█████████▋| 476/492 [6:07:09<30:37, 114.85s/it] 97%|█████████▋| 477/492 [6:09:04<28:44, 114.93s/it] 97%|█████████▋| 478/492 [6:10:59<26:49, 114.94s/it] 97%|█████████▋| 479/492 [6:12:54<24:52, 114.79s/it] 98%|█████████▊| 480/492 [6:14:49<22:57, 114.82s/it]                                                     98%|█████████▊| 480/492 [6:14:49<22:57, 114.82s/it] 98%|█████████▊| 481/492 [6:16:43<21:01, 114.67s/it] 98%|█████████▊| 482/492 [6:18:38<19:07, 114.70s/it] 98%|█████████▊| 483/492 [6:20:33<17:12, 114.70s/it] 98%|█████████▊| 484/492 [6:22:28<15:18, 114.86s/it] 99%|█████████▊| 485/492 [6:24:23<13:24, 114.91s/it]                                                     99%|█████████▊| 485/492 [6:24:23<13:24, 114.91s/it] 99%|█████████▉| 486/492 [6:26:18<11:29, 114.95s/it] 99%|█████████▉| 487/492 [6:28:13<09:34, 114.98s/it] 99%|█████████▉| 488/492 [6:30:08<07:39, 114.94s/it] 99%|█████████▉| 489/492 [6:32:02<05:44, 114.87s/it]100%|█████████▉| 490/492 [6:33:57<03:49, 114.92s/it]                                                    100%|█████████▉| 490/492 [6:33:57<03:49, 114.92s/it]100%|█████████▉| 491/492 [6:35:52<01:54, 114.85s/it]100%|██████████| 492/492 [6:37:48<00:00, 115.05s/it]/workspace/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
wandb: Adding directory to artifact (./model_training/deepseek_prover_sft_no_err/checkpoints-random-09-07-09-00/checkpoint-492)... Done. 4.7s
                                                    100%|██████████| 492/492 [6:38:02<00:00, 115.05s/it]/workspace/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
{'eval_loss': 0.08962889015674591, 'eval_runtime': 577.8097, 'eval_samples_per_second': 1.731, 'eval_steps_per_second': 0.216, 'epoch': 3.66}
{'loss': 0.0853, 'grad_norm': 0.06826679408550262, 'learning_rate': 1.7190725845048827e-06, 'epoch': 3.7}
{'loss': 0.0857, 'grad_norm': 0.06725401431322098, 'learning_rate': 1.2877220681510927e-06, 'epoch': 3.74}
{'loss': 0.0826, 'grad_norm': 0.06796524673700333, 'learning_rate': 9.178875315329183e-07, 'epoch': 3.78}
{'loss': 0.086, 'grad_norm': 0.05944016948342323, 'learning_rate': 6.100360177619946e-07, 'epoch': 3.82}
{'loss': 0.0765, 'grad_norm': 0.06194449961185455, 'learning_rate': 3.6455629509730136e-07, 'epoch': 3.86}
{'loss': 0.0843, 'grad_norm': 0.06110742315649986, 'learning_rate': 1.8175836599173546e-07, 'epoch': 3.9}
{'loss': 0.0825, 'grad_norm': 0.07199981808662415, 'learning_rate': 6.187307560754363e-08, 'epoch': 3.94}
{'loss': 0.0822, 'grad_norm': 0.06428951770067215, 'learning_rate': 5.051820295032261e-09, 'epoch': 3.98}
{'train_runtime': 23889.9019, 'train_samples_per_second': 1.319, 'train_steps_per_second': 0.021, 'train_loss': 0.032160074245638964, 'epoch': 4.0}
Finetuning Finished.
wandb: - 6521.017 MB of 6521.017 MB uploaded (17.627 MB deduped)wandb: \ 6521.017 MB of 6521.017 MB uploaded (17.627 MB deduped)wandb: | 6521.017 MB of 6521.017 MB uploaded (17.627 MB deduped)wandb: / 6521.017 MB of 6521.017 MB uploaded (17.627 MB deduped)wandb: - 6521.017 MB of 6521.043 MB uploaded (17.627 MB deduped)wandb: \ 6521.043 MB of 6521.043 MB uploaded (17.627 MB deduped)wandb: 
wandb: Run history:
wandb:               eval/loss █▃▁
wandb:            eval/runtime █▆▁
wandb: eval/samples_per_second ▁▃█
wandb:   eval/steps_per_second ▁▁▁
wandb:             train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:       train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:         train/grad_norm ▁▃▁▃▄▂▃▃█▄▂▄▂▃▇▃▃▅▇▂▃▄▄▄▃▂▄▃▂▄▄▄▄▃▃▃▅▃
wandb:     train/learning_rate ██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb:              train/loss ▅▅▄▃█▅▆▄▃▅▃▅▅▄▁▃▃▅▄▃▅▄▅▄▁▂▃▄▄▄▅▅▄▅▂▅▄▄
wandb: 
wandb: Run summary:
wandb:                eval/loss 0.08963
wandb:             eval/runtime 577.8097
wandb:  eval/samples_per_second 1.731
wandb:    eval/steps_per_second 0.216
wandb:               total_flos 3.138580840489943e+18
wandb:              train/epoch 3.99797
wandb:        train/global_step 492
wandb:          train/grad_norm 0.06429
wandb:      train/learning_rate 0.0
wandb:               train/loss 0.0822
wandb:               train_loss 0.03216
wandb:            train_runtime 23889.9019
wandb: train_samples_per_second 1.319
wandb:   train_steps_per_second 0.021
wandb: 
wandb: 🚀 View run deepseek_prover_sft_no_err-random-09-07-09-00 at: https://wandb.ai/tcwong/decoder/runs/vff5tzyv
wandb: ⭐️ View project at: https://wandb.ai/tcwong/decoder
wandb: Synced 5 W&B file(s), 0 media file(s), 44 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240907_200206-vff5tzyv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
