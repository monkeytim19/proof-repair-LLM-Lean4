nohup: ignoring input
Finetuning starting.
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [01:11<01:11, 71.41s/it]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:54<00:00, 54.94s/it]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:54<00:00, 57.47s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.20s/it]
trainable params: 10,644,480 || all params: 6,901,373,952 || trainable%: 0.1542
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 7876 examples [00:00, 14401.01 examples/s]Generating train split: 7876 examples [00:00, 14177.22 examples/s]
Generating valid split: 0 examples [00:00, ? examples/s]Generating valid split: 1000 examples [00:00, 10145.70 examples/s]
Map:   0%|          | 0/7876 [00:00<?, ? examples/s]Map:  13%|â–ˆâ–Ž        | 1000/7876 [00:00<00:05, 1207.48 examples/s]Map:  25%|â–ˆâ–ˆâ–Œ       | 2000/7876 [00:01<00:04, 1238.39 examples/s]Map:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3000/7876 [00:02<00:03, 1265.59 examples/s]Map:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4000/7876 [00:03<00:03, 1269.63 examples/s]Map:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5000/7876 [00:03<00:02, 1295.90 examples/s]Map:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6000/7876 [00:04<00:01, 1307.48 examples/s]Map:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 7000/7876 [00:05<00:00, 1313.97 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7876/7876 [00:06<00:00, 1299.32 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7876/7876 [00:06<00:00, 1284.77 examples/s]
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1344.30 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1315.94 examples/s]
[2024-09-07 21:23:17,439] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
df: /root/.triton/autotune: No such file or directory
/workspace/venv/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/workspace/venv/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/workspace/venv/lib/python3.10/site-packages/transformers/trainer.py:3108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)
wandb: Currently logged in as: tcwong. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.9 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.7
wandb: Run data is saved locally in /workspace/wandb/run-20240907_212339-xjbmhng9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deepseek_prover_base_no_err-by_file-09-07-08-59
wandb: â­ï¸ View project at https://wandb.ai/tcwong/decoder
wandb: ðŸš€ View run at https://wandb.ai/tcwong/decoder/runs/xjbmhng9
[93m [WARNING] [0m async_io requires the dev libaio .so object and headers but these were not found.
[93m [WARNING] [0m async_io: please install the libaio-dev package with apt
[93m [WARNING] [0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
  0%|          | 0/492 [00:00<?, ?it/s]/workspace/venv/lib/python3.10/site-packages/transformers/trainer.py:2843: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint_rng_state = torch.load(rng_file)
W0907 21:23:56.934000 133425874043328 torch/_dynamo/variables/tensor.py:715] [17/0] Graph break from `Tensor.item()`, consider setting:
W0907 21:23:56.934000 133425874043328 torch/_dynamo/variables/tensor.py:715] [17/0]     torch._dynamo.config.capture_scalar_outputs = True
W0907 21:23:56.934000 133425874043328 torch/_dynamo/variables/tensor.py:715] [17/0] or:
W0907 21:23:56.934000 133425874043328 torch/_dynamo/variables/tensor.py:715] [17/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1
W0907 21:23:56.934000 133425874043328 torch/_dynamo/variables/tensor.py:715] [17/0] to include these operations in the captured graph.
W0907 21:23:56.934000 133425874043328 torch/_dynamo/variables/tensor.py:715] [17/0] 
The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.
/workspace/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 351/492 [02:36<01:02,  2.24it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 352/492 [04:31<02:07,  1.10it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 353/492 [06:25<03:36,  1.56s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 354/492 [08:18<05:41,  2.48s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/492 [10:12<08:34,  3.76s/it]                                                  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 355/492 [10:12<08:34,  3.76s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 356/492 [12:07<12:35,  5.55s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 357/492 [14:01<18:00,  8.00s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 358/492 [15:55<25:17, 11.32s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 359/492 [17:49<34:51, 15.73s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 360/492 [19:43<47:02, 21.38s/it]                                                  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 360/492 [19:43<47:02, 21.38s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 361/492 [21:38<1:02:09, 28.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 362/492 [23:32<1:19:50, 36.85s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 363/492 [25:26<1:39:38, 46.34s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 364/492 [27:20<2:00:20, 56.41s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/492 [29:13<2:20:41, 66.47s/it]                                                    74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 365/492 [29:13<2:20:41, 66.47s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 366/492 [31:07<2:39:36, 76.00s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 367/492 [33:01<2:55:56, 84.45s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 368/492 [34:56<3:09:22, 91.64s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 369/492 [36:50<3:19:38, 97.38s/it]/workspace/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 370/492 [38:49<3:29:50, 103.20s/it]                                                     75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 370/492 [38:49<3:29:50, 103.20s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 371/492 [40:43<3:34:08, 106.18s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 372/492 [42:37<3:36:57, 108.48s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 373/492 [44:31<3:38:20, 110.09s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 374/492 [46:25<3:38:58, 111.34s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/492 [48:20<3:38:52, 112.25s/it]                                                     76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 375/492 [48:20<3:38:52, 112.25s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 376/492 [50:13<3:37:47, 112.65s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 377/492 [52:07<3:36:35, 113.00s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 378/492 [54:01<3:35:03, 113.19s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 379/492 [55:55<3:33:32, 113.39s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 380/492 [57:49<3:32:12, 113.68s/it]                                                     77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 380/492 [57:49<3:32:12, 113.68s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 381/492 [59:43<3:30:43, 113.90s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 382/492 [1:01:37<3:28:44, 113.86s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 383/492 [1:03:32<3:27:21, 114.14s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 384/492 [1:05:26<3:25:30, 114.17s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 385/492 [1:07:20<3:23:34, 114.15s/it]                                                       78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 385/492 [1:07:20<3:23:34, 114.15s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 386/492 [1:09:14<3:21:31, 114.07s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 387/492 [1:11:09<3:19:50, 114.20s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 388/492 [1:13:03<3:18:02, 114.25s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 389/492 [1:14:57<3:16:07, 114.25s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 390/492 [1:16:52<3:14:16, 114.28s/it]                                                       79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 390/492 [1:16:52<3:14:16, 114.28s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 391/492 [1:18:46<3:12:23, 114.29s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 392/492 [1:20:40<3:10:24, 114.24s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 393/492 [1:22:34<3:08:19, 114.13s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 394/492 [1:24:28<3:06:14, 114.03s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 395/492 [1:26:22<3:04:19, 114.02s/it]                                                       80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 395/492 [1:26:22<3:04:19, 114.02s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 396/492 [1:28:15<3:02:14, 113.90s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 397/492 [1:30:09<3:00:15, 113.84s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 398/492 [1:32:03<2:58:27, 113.91s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 399/492 [1:33:57<2:56:29, 113.87s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 400/492 [1:35:51<2:54:35, 113.87s/it]                                                       81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 400/492 [1:35:51<2:54:35, 113.87s/it]{'loss': 0.1051, 'grad_norm': 0.12189479172229767, 'learning_rate': 2.1889952770883643e-05, 'epoch': 2.89}
{'loss': 0.1066, 'grad_norm': 0.09821608662605286, 'learning_rate': 2.043849824442124e-05, 'epoch': 2.93}
{'loss': 0.1076, 'grad_norm': 0.0908147543668747, 'learning_rate': 1.9024375265982384e-05, 'epoch': 2.97}
{'loss': 0.1134, 'grad_norm': 0.11563821136951447, 'learning_rate': 1.764936965146773e-05, 'epoch': 3.01}
{'loss': 0.1081, 'grad_norm': 0.10024692863225937, 'learning_rate': 1.631521781767214e-05, 'epoch': 3.05}
{'loss': 0.0996, 'grad_norm': 0.11522582173347473, 'learning_rate': 1.502360458946232e-05, 'epoch': 3.09}
{'loss': 0.1155, 'grad_norm': 0.1005687341094017, 'learning_rate': 1.3776161072106702e-05, 'epoch': 3.13}
{'loss': 0.1184, 'grad_norm': 0.10551727563142776, 'learning_rate': 1.257446259144494e-05, 'epoch': 3.17}
{'loss': 0.1071, 'grad_norm': 0.09149405360221863, 'learning_rate': 1.1420026704498077e-05, 'epoch': 3.21}
{'loss': 0.0984, 'grad_norm': 0.08743679523468018, 'learning_rate': 1.031431128303153e-05, 'epoch': 3.25}

  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|â–         | 2/125 [00:04<04:22,  2.14s/it][A
  2%|â–         | 3/125 [00:08<06:23,  3.14s/it][A
  3%|â–Ž         | 4/125 [00:13<07:23,  3.66s/it][A
  4%|â–         | 5/125 [00:17<07:55,  3.97s/it][A
  5%|â–         | 6/125 [00:22<08:17,  4.18s/it][A
  6%|â–Œ         | 7/125 [00:27<08:27,  4.30s/it][A
  6%|â–‹         | 8/125 [00:31<08:33,  4.39s/it][A
  7%|â–‹         | 9/125 [00:36<08:37,  4.46s/it][A
  8%|â–Š         | 10/125 [00:40<08:37,  4.50s/it][A
  9%|â–‰         | 11/125 [00:45<08:35,  4.52s/it][A
 10%|â–‰         | 12/125 [00:49<08:32,  4.53s/it][A
 10%|â–ˆ         | 13/125 [00:54<08:30,  4.56s/it][A
 11%|â–ˆ         | 14/125 [00:59<08:29,  4.59s/it][A
 12%|â–ˆâ–        | 15/125 [01:03<08:26,  4.60s/it][A
 13%|â–ˆâ–Ž        | 16/125 [01:08<08:21,  4.60s/it][A
 14%|â–ˆâ–Ž        | 17/125 [01:13<08:16,  4.59s/it][A
 14%|â–ˆâ–        | 18/125 [01:17<08:11,  4.59s/it][A
 15%|â–ˆâ–Œ        | 19/125 [01:22<08:06,  4.59s/it][A
 16%|â–ˆâ–Œ        | 20/125 [01:26<08:01,  4.58s/it][A
 17%|â–ˆâ–‹        | 21/125 [01:31<07:57,  4.59s/it][A
 18%|â–ˆâ–Š        | 22/125 [01:36<07:53,  4.59s/it][A
 18%|â–ˆâ–Š        | 23/125 [01:40<07:48,  4.60s/it][A
 19%|â–ˆâ–‰        | 24/125 [01:45<07:44,  4.60s/it][A
 20%|â–ˆâ–ˆ        | 25/125 [01:49<07:40,  4.61s/it][A
 21%|â–ˆâ–ˆ        | 26/125 [01:54<07:34,  4.59s/it][A
 22%|â–ˆâ–ˆâ–       | 27/125 [01:59<07:30,  4.59s/it][A
 22%|â–ˆâ–ˆâ–       | 28/125 [02:03<07:25,  4.59s/it][A
 23%|â–ˆâ–ˆâ–Ž       | 29/125 [02:08<07:20,  4.59s/it][A
 24%|â–ˆâ–ˆâ–       | 30/125 [02:12<07:17,  4.60s/it][A
 25%|â–ˆâ–ˆâ–       | 31/125 [02:17<07:12,  4.60s/it][A
 26%|â–ˆâ–ˆâ–Œ       | 32/125 [02:21<07:06,  4.59s/it][A
 26%|â–ˆâ–ˆâ–‹       | 33/125 [02:26<07:03,  4.60s/it][A
 27%|â–ˆâ–ˆâ–‹       | 34/125 [02:31<06:59,  4.61s/it][A
 28%|â–ˆâ–ˆâ–Š       | 35/125 [02:35<06:53,  4.60s/it][A
 29%|â–ˆâ–ˆâ–‰       | 36/125 [02:40<06:49,  4.60s/it][A
 30%|â–ˆâ–ˆâ–‰       | 37/125 [02:44<06:44,  4.60s/it][A
 30%|â–ˆâ–ˆâ–ˆ       | 38/125 [02:49<06:39,  4.59s/it][A
 31%|â–ˆâ–ˆâ–ˆ       | 39/125 [02:54<06:34,  4.58s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 40/125 [02:58<06:30,  4.59s/it][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 41/125 [03:03<06:25,  4.59s/it][A
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/125 [03:07<06:19,  4.58s/it][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 43/125 [03:12<06:17,  4.60s/it][A
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 44/125 [03:17<06:11,  4.59s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/125 [03:21<06:06,  4.58s/it][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 46/125 [03:26<06:01,  4.58s/it][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 47/125 [03:30<05:57,  4.58s/it][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/125 [03:35<05:54,  4.60s/it][A
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 49/125 [03:40<05:50,  4.61s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 50/125 [03:44<05:45,  4.61s/it][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 51/125 [03:49<05:42,  4.63s/it][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 52/125 [03:54<05:39,  4.65s/it][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/125 [03:58<05:33,  4.63s/it][A
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 54/125 [04:03<05:27,  4.61s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 55/125 [04:07<05:22,  4.61s/it][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/125 [04:12<05:17,  4.60s/it][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 57/125 [04:17<05:13,  4.61s/it][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 58/125 [04:21<05:08,  4.61s/it][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/125 [04:26<05:03,  4.60s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 60/125 [04:30<04:59,  4.60s/it][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 61/125 [04:35<04:54,  4.61s/it][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 62/125 [04:40<04:49,  4.60s/it][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 63/125 [04:44<04:45,  4.60s/it][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/125 [04:49<04:40,  4.60s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 65/125 [04:53<04:36,  4.60s/it][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 66/125 [04:58<04:30,  4.58s/it][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 67/125 [05:02<04:24,  4.57s/it][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 68/125 [05:07<04:20,  4.57s/it][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 69/125 [05:12<04:15,  4.57s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 70/125 [05:16<04:11,  4.57s/it][A
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 71/125 [05:21<04:08,  4.59s/it][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 72/125 [05:25<04:02,  4.58s/it][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 73/125 [05:30<03:59,  4.60s/it][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 74/125 [05:35<03:55,  4.61s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 75/125 [05:39<03:51,  4.63s/it][A
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 76/125 [05:44<03:47,  4.63s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 77/125 [05:49<03:42,  4.63s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 78/125 [05:53<03:37,  4.62s/it][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 79/125 [05:58<03:33,  4.63s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/125 [06:02<03:29,  4.65s/it][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 81/125 [06:07<03:24,  4.64s/it][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 82/125 [06:12<03:18,  4.63s/it][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 83/125 [06:16<03:13,  4.60s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 84/125 [06:21<03:08,  4.59s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 85/125 [06:25<03:03,  4.58s/it][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 86/125 [06:30<02:58,  4.58s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 87/125 [06:35<02:54,  4.60s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 88/125 [06:39<02:51,  4.62s/it][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 89/125 [06:44<02:46,  4.63s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 90/125 [06:48<02:41,  4.61s/it][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 91/125 [06:53<02:37,  4.62s/it][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 92/125 [06:58<02:31,  4.60s/it][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 93/125 [07:02<02:26,  4.58s/it][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 94/125 [07:07<02:22,  4.60s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 95/125 [07:12<02:18,  4.62s/it][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 96/125 [07:16<02:13,  4.60s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 97/125 [07:21<02:08,  4.59s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 98/125 [07:25<02:03,  4.59s/it][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 99/125 [07:30<01:59,  4.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 100/125 [07:34<01:54,  4.59s/it][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 101/125 [07:39<01:50,  4.58s/it][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 102/125 [07:44<01:45,  4.59s/it][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 103/125 [07:48<01:41,  4.61s/it][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 104/125 [07:53<01:37,  4.62s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/125 [07:58<01:32,  4.63s/it][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 106/125 [08:02<01:27,  4.62s/it][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 107/125 [08:07<01:23,  4.62s/it][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 108/125 [08:11<01:18,  4.63s/it][A
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 109/125 [08:16<01:13,  4.61s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 110/125 [08:21<01:09,  4.60s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 111/125 [08:25<01:04,  4.60s/it][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 112/125 [08:30<00:59,  4.60s/it][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 113/125 [08:34<00:55,  4.60s/it][A
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 114/125 [08:39<00:50,  4.59s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 115/125 [08:44<00:45,  4.60s/it][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 116/125 [08:48<00:41,  4.60s/it][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 117/125 [08:53<00:36,  4.61s/it][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/125 [08:57<00:32,  4.61s/it][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 119/125 [09:02<00:27,  4.62s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 120/125 [09:07<00:23,  4.60s/it][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 121/125 [09:11<00:18,  4.59s/it][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 122/125 [09:16<00:13,  4.58s/it][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 123/125 [09:20<00:09,  4.60s/it][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 124/125 [09:25<00:04,  4.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [09:30<00:00,  4.61s/it][A                                                      
                                                 [A 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 400/492 [1:45:26<2:54:35, 113.87s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [09:30<00:00,  4.61s/it][A
                                                 [A/workspace/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
wandb: Adding directory to artifact (./model_training/deepseek_prover_base_no_err/checkpoints-by_file-09-07-08-59/checkpoint-400)... Done. 4.2s
/workspace/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 401/492 [1:47:31<7:19:16, 289.63s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 402/492 [1:49:25<5:55:24, 236.94s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 403/492 [1:51:19<4:56:53, 200.16s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 404/492 [1:53:13<4:15:33, 174.24s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/492 [1:55:07<3:46:29, 156.20s/it]                                                       82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 405/492 [1:55:07<3:46:29, 156.20s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 406/492 [1:57:01<3:25:53, 143.65s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 407/492 [1:58:55<3:10:55, 134.77s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 408/492 [2:00:49<2:59:50, 128.45s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 409/492 [2:02:43<2:51:54, 124.28s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 410/492 [2:04:37<2:45:35, 121.16s/it]                                                       83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 410/492 [2:04:37<2:45:35, 121.16s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 411/492 [2:06:32<2:40:52, 119.16s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 412/492 [2:08:26<2:36:52, 117.66s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 413/492 [2:10:20<2:33:27, 116.55s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 414/492 [2:12:14<2:30:32, 115.81s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/492 [2:14:08<2:28:01, 115.34s/it]                                                       84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 415/492 [2:14:08<2:28:01, 115.34s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 416/492 [2:16:02<2:25:32, 114.90s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 417/492 [2:17:56<2:23:22, 114.70s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 418/492 [2:19:50<2:21:04, 114.38s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 419/492 [2:21:44<2:19:08, 114.36s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 420/492 [2:23:38<2:17:03, 114.22s/it]                                                       85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 420/492 [2:23:38<2:17:03, 114.22s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 421/492 [2:25:32<2:14:51, 113.97s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 422/492 [2:27:25<2:12:49, 113.85s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 423/492 [2:29:19<2:10:55, 113.85s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 424/492 [2:31:13<2:09:07, 113.94s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 425/492 [2:33:08<2:07:32, 114.21s/it]                                                       86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 425/492 [2:33:08<2:07:32, 114.21s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 426/492 [2:35:02<2:05:36, 114.18s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 427/492 [2:36:56<2:03:38, 114.14s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 428/492 [2:38:50<2:01:35, 114.00s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 429/492 [2:40:44<1:59:44, 114.05s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430/492 [2:42:38<1:57:46, 113.98s/it]                                                       87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 430/492 [2:42:38<1:57:46, 113.98s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 431/492 [2:44:31<1:55:45, 113.86s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 432/492 [2:46:25<1:53:53, 113.90s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 433/492 [2:48:20<1:52:05, 113.99s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 434/492 [2:50:14<1:50:11, 113.99s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 435/492 [2:52:08<1:48:22, 114.07s/it]                                                       88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 435/492 [2:52:08<1:48:22, 114.07s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 436/492 [2:54:02<1:46:24, 114.01s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 437/492 [2:55:56<1:44:31, 114.03s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 438/492 [2:57:49<1:42:31, 113.91s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 439/492 [2:59:43<1:40:29, 113.77s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440/492 [3:01:37<1:38:45, 113.96s/it]                                                       89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 440/492 [3:01:37<1:38:45, 113.96s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 441/492 [3:03:31<1:36:45, 113.84s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 442/492 [3:05:25<1:34:54, 113.88s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 443/492 [3:07:18<1:32:55, 113.78s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 444/492 [3:09:12<1:31:05, 113.86s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 445/492 [3:11:07<1:29:15, 113.94s/it]                                                       90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 445/492 [3:11:07<1:29:15, 113.94s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 446/492 [3:13:01<1:27:23, 113.99s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 447/492 [3:14:54<1:25:23, 113.84s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 448/492 [3:16:48<1:23:35, 113.98s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 449/492 [3:18:43<1:21:42, 114.02s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/492 [3:20:37<1:19:52, 114.10s/it]                                                       91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/492 [3:20:37<1:19:52, 114.10s/it]{'eval_loss': 0.14250527322292328, 'eval_runtime': 575.342, 'eval_samples_per_second': 1.738, 'eval_steps_per_second': 0.217, 'epoch': 3.25}
{'loss': 0.1075, 'grad_norm': 0.1152808740735054, 'learning_rate': 9.258712672491415e-06, 'epoch': 3.29}
{'loss': 0.1055, 'grad_norm': 0.0870693102478981, 'learning_rate': 8.254563928638893e-06, 'epoch': 3.33}
{'loss': 0.1162, 'grad_norm': 0.1064496636390686, 'learning_rate': 7.3031331341093915e-06, 'epoch': 3.37}
{'loss': 0.1032, 'grad_norm': 0.10074327141046524, 'learning_rate': 6.405621797022848e-06, 'epoch': 3.41}
{'loss': 0.1057, 'grad_norm': 0.11636592447757721, 'learning_rate': 5.563163333667099e-06, 'epoch': 3.45}
{'loss': 0.105, 'grad_norm': 0.08998982608318329, 'learning_rate': 4.776821637170526e-06, 'epoch': 3.49}
{'loss': 0.1032, 'grad_norm': 0.09578435868024826, 'learning_rate': 4.047589733971646e-06, 'epoch': 3.54}
{'loss': 0.1046, 'grad_norm': 0.10539178550243378, 'learning_rate': 3.376388529782215e-06, 'epoch': 3.58}
{'loss': 0.0981, 'grad_norm': 0.1038966253399849, 'learning_rate': 2.7640656466274782e-06, 'epoch': 3.62}
{'loss': 0.1014, 'grad_norm': 0.09623471647500992, 'learning_rate': 2.2113943524323167e-06, 'epoch': 3.66}

  0%|          | 0/125 [00:00<?, ?it/s][A
  2%|â–         | 2/125 [00:04<04:46,  2.33s/it][A
  2%|â–         | 3/125 [00:09<06:36,  3.25s/it][A
  3%|â–Ž         | 4/125 [00:13<07:31,  3.73s/it][A
  4%|â–         | 5/125 [00:18<08:01,  4.01s/it][A
  5%|â–         | 6/125 [00:22<08:20,  4.21s/it][A
  6%|â–Œ         | 7/125 [00:27<08:29,  4.32s/it][A
  6%|â–‹         | 8/125 [00:32<08:34,  4.40s/it][A
  7%|â–‹         | 9/125 [00:36<08:38,  4.47s/it][A
  8%|â–Š         | 10/125 [00:41<08:37,  4.50s/it][A
  9%|â–‰         | 11/125 [00:45<08:36,  4.53s/it][A
 10%|â–‰         | 12/125 [00:50<08:32,  4.54s/it][A
 10%|â–ˆ         | 13/125 [00:54<08:30,  4.56s/it][A
 11%|â–ˆ         | 14/125 [00:59<08:30,  4.60s/it][A
 12%|â–ˆâ–        | 15/125 [01:04<08:26,  4.60s/it][A
 13%|â–ˆâ–Ž        | 16/125 [01:08<08:21,  4.60s/it][A
 14%|â–ˆâ–Ž        | 17/125 [01:13<08:16,  4.59s/it][A
 14%|â–ˆâ–        | 18/125 [01:18<08:11,  4.59s/it][A
 15%|â–ˆâ–Œ        | 19/125 [01:22<08:06,  4.59s/it][A
 16%|â–ˆâ–Œ        | 20/125 [01:27<08:01,  4.59s/it][A
 17%|â–ˆâ–‹        | 21/125 [01:31<07:57,  4.59s/it][A
 18%|â–ˆâ–Š        | 22/125 [01:36<07:53,  4.59s/it][A
 18%|â–ˆâ–Š        | 23/125 [01:41<07:48,  4.60s/it][A
 19%|â–ˆâ–‰        | 24/125 [01:45<07:44,  4.60s/it][A
 20%|â–ˆâ–ˆ        | 25/125 [01:50<07:40,  4.61s/it][A
 21%|â–ˆâ–ˆ        | 26/125 [01:54<07:34,  4.59s/it][A
 22%|â–ˆâ–ˆâ–       | 27/125 [01:59<07:30,  4.60s/it][A
 22%|â–ˆâ–ˆâ–       | 28/125 [02:03<07:25,  4.60s/it][A
 23%|â–ˆâ–ˆâ–Ž       | 29/125 [02:08<07:20,  4.59s/it][A
 24%|â–ˆâ–ˆâ–       | 30/125 [02:13<07:17,  4.61s/it][A
 25%|â–ˆâ–ˆâ–       | 31/125 [02:17<07:12,  4.60s/it][A
 26%|â–ˆâ–ˆâ–Œ       | 32/125 [02:22<07:07,  4.59s/it][A
 26%|â–ˆâ–ˆâ–‹       | 33/125 [02:27<07:03,  4.60s/it][A
 27%|â–ˆâ–ˆâ–‹       | 34/125 [02:31<06:59,  4.61s/it][A
 28%|â–ˆâ–ˆâ–Š       | 35/125 [02:36<06:54,  4.60s/it][A
 29%|â–ˆâ–ˆâ–‰       | 36/125 [02:40<06:49,  4.60s/it][A
 30%|â–ˆâ–ˆâ–‰       | 37/125 [02:45<06:44,  4.60s/it][A
 30%|â–ˆâ–ˆâ–ˆ       | 38/125 [02:49<06:39,  4.59s/it][A
 31%|â–ˆâ–ˆâ–ˆ       | 39/125 [02:54<06:34,  4.59s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 40/125 [02:59<06:30,  4.59s/it][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 41/125 [03:03<06:25,  4.59s/it][A
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 42/125 [03:08<06:19,  4.58s/it][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 43/125 [03:12<06:17,  4.60s/it][A
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 44/125 [03:17<06:11,  4.59s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/125 [03:22<06:06,  4.58s/it][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 46/125 [03:26<06:01,  4.58s/it][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 47/125 [03:31<05:57,  4.58s/it][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/125 [03:35<05:54,  4.60s/it][A
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 49/125 [03:40<05:50,  4.61s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 50/125 [03:45<05:45,  4.61s/it][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 51/125 [03:49<05:42,  4.63s/it][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 52/125 [03:54<05:39,  4.65s/it][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/125 [03:59<05:33,  4.63s/it][A
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 54/125 [04:03<05:27,  4.61s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 55/125 [04:08<05:22,  4.61s/it][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/125 [04:12<05:17,  4.60s/it][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 57/125 [04:17<05:13,  4.61s/it][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 58/125 [04:22<05:08,  4.61s/it][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 59/125 [04:26<05:03,  4.60s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 60/125 [04:31<04:59,  4.60s/it][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 61/125 [04:35<04:54,  4.61s/it][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 62/125 [04:40<04:49,  4.60s/it][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 63/125 [04:45<04:45,  4.60s/it][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/125 [04:49<04:40,  4.60s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 65/125 [04:54<04:36,  4.60s/it][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 66/125 [04:58<04:30,  4.58s/it][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 67/125 [05:03<04:25,  4.57s/it][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 68/125 [05:07<04:20,  4.58s/it][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 69/125 [05:12<04:15,  4.57s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 70/125 [05:17<04:11,  4.57s/it][A
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 71/125 [05:21<04:08,  4.60s/it][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 72/125 [05:26<04:02,  4.58s/it][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 73/125 [05:30<03:59,  4.60s/it][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 74/125 [05:35<03:55,  4.61s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 75/125 [05:40<03:51,  4.63s/it][A
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 76/125 [05:44<03:47,  4.63s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 77/125 [05:49<03:42,  4.63s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 78/125 [05:54<03:37,  4.62s/it][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 79/125 [05:58<03:33,  4.64s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/125 [06:03<03:29,  4.65s/it][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 81/125 [06:08<03:24,  4.64s/it][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 82/125 [06:12<03:18,  4.63s/it][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 83/125 [06:17<03:13,  4.61s/it][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 84/125 [06:21<03:08,  4.59s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 85/125 [06:26<03:03,  4.58s/it][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 86/125 [06:30<02:58,  4.58s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 87/125 [06:35<02:54,  4.60s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 88/125 [06:40<02:51,  4.62s/it][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 89/125 [06:44<02:46,  4.63s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 90/125 [06:49<02:41,  4.61s/it][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 91/125 [06:54<02:37,  4.62s/it][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 92/125 [06:58<02:31,  4.60s/it][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 93/125 [07:03<02:26,  4.59s/it][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 94/125 [07:07<02:22,  4.61s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 95/125 [07:12<02:18,  4.62s/it][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 96/125 [07:17<02:13,  4.61s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 97/125 [07:21<02:08,  4.59s/it][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 98/125 [07:26<02:03,  4.59s/it][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 99/125 [07:30<01:59,  4.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 100/125 [07:35<01:54,  4.59s/it][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 101/125 [07:39<01:50,  4.58s/it][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 102/125 [07:44<01:45,  4.59s/it][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 103/125 [07:49<01:41,  4.60s/it][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 104/125 [07:53<01:37,  4.62s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/125 [07:58<01:32,  4.63s/it][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 106/125 [08:03<01:27,  4.62s/it][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 107/125 [08:07<01:23,  4.62s/it][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 108/125 [08:12<01:18,  4.63s/it][A
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 109/125 [08:16<01:13,  4.61s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 110/125 [08:21<01:09,  4.60s/it][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 111/125 [08:26<01:04,  4.60s/it][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 112/125 [08:30<00:59,  4.60s/it][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 113/125 [08:35<00:55,  4.60s/it][A
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 114/125 [08:39<00:50,  4.58s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 115/125 [08:44<00:45,  4.59s/it][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 116/125 [08:49<00:41,  4.59s/it][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 117/125 [08:53<00:36,  4.61s/it][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/125 [08:58<00:32,  4.61s/it][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 119/125 [09:03<00:27,  4.62s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 120/125 [09:07<00:22,  4.60s/it][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 121/125 [09:12<00:18,  4.59s/it][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 122/125 [09:16<00:13,  4.58s/it][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 123/125 [09:21<00:09,  4.60s/it][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 124/125 [09:25<00:04,  4.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [09:30<00:00,  4.61s/it][A                                                      
                                                 [A 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 450/492 [3:30:12<1:19:52, 114.10s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [09:30<00:00,  4.61s/it][A
                                                 [A/workspace/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
wandb: Adding directory to artifact (./model_training/deepseek_prover_base_no_err/checkpoints-by_file-09-07-08-59/checkpoint-450)... Done. 4.3s
/workspace/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 451/492 [3:32:17<3:18:07, 289.93s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 452/492 [3:34:11<2:38:04, 237.12s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 453/492 [3:36:05<2:10:03, 200.09s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 454/492 [3:37:59<1:50:20, 174.23s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/492 [3:39:53<1:36:17, 156.16s/it]                                                       92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 455/492 [3:39:53<1:36:17, 156.16s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 456/492 [3:41:46<1:26:02, 143.42s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 457/492 [3:43:40<1:18:27, 134.49s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 458/492 [3:45:34<1:12:44, 128.37s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 459/492 [3:47:28<1:08:17, 124.17s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 460/492 [3:49:22<1:04:35, 121.11s/it]                                                       93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 460/492 [3:49:22<1:04:35, 121.11s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 461/492 [3:51:17<1:01:30, 119.06s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 462/492 [3:53:10<58:44, 117.50s/it]   94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 463/492 [3:55:04<56:17, 116.46s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 464/492 [3:56:59<54:03, 115.82s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/492 [3:58:53<51:52, 115.28s/it]                                                     95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 465/492 [3:58:53<51:52, 115.28s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 466/492 [4:00:47<49:49, 114.99s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 467/492 [4:02:42<47:51, 114.85s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 468/492 [4:04:36<45:51, 114.63s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 469/492 [4:06:30<43:50, 114.37s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 470/492 [4:08:24<41:56, 114.36s/it]                                                     96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 470/492 [4:08:24<41:56, 114.36s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 471/492 [4:10:18<40:00, 114.32s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 472/492 [4:12:12<38:05, 114.27s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 473/492 [4:14:07<36:11, 114.30s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 474/492 [4:16:01<34:17, 114.29s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 475/492 [4:17:54<32:18, 114.06s/it]                                                     97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 475/492 [4:17:54<32:18, 114.06s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 476/492 [4:19:48<30:24, 114.03s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 477/492 [4:21:43<28:31, 114.10s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 478/492 [4:23:37<26:36, 114.07s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 479/492 [4:25:31<24:43, 114.09s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 480/492 [4:27:25<22:50, 114.21s/it]                                                     98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 480/492 [4:27:25<22:50, 114.21s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 481/492 [4:29:20<20:56, 114.27s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 482/492 [4:31:14<19:02, 114.25s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 483/492 [4:33:08<17:08, 114.23s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 484/492 [4:35:02<15:12, 114.07s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 485/492 [4:36:56<13:18, 114.08s/it]                                                     99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 485/492 [4:36:56<13:18, 114.08s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 486/492 [4:38:50<11:24, 114.06s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 487/492 [4:40:44<09:29, 113.99s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 488/492 [4:42:38<07:36, 114.03s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 489/492 [4:44:31<05:41, 113.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 490/492 [4:46:25<03:47, 113.91s/it]                                                    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 490/492 [4:46:25<03:47, 113.91s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 491/492 [4:48:19<01:53, 113.85s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 492/492 [4:50:13<00:00, 113.90s/it]/workspace/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
wandb: Adding directory to artifact (./model_training/deepseek_prover_base_no_err/checkpoints-by_file-09-07-08-59/checkpoint-492)... Done. 8.6s
                                                    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 492/492 [4:50:35<00:00, 113.90s/it]/workspace/venv/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
{'eval_loss': 0.1424967348575592, 'eval_runtime': 575.2181, 'eval_samples_per_second': 1.738, 'eval_steps_per_second': 0.217, 'epoch': 3.66}
{'loss': 0.1024, 'grad_norm': 0.12714102864265442, 'learning_rate': 1.7190725845048827e-06, 'epoch': 3.7}
{'loss': 0.1029, 'grad_norm': 0.10180765390396118, 'learning_rate': 1.2877220681510927e-06, 'epoch': 3.74}
{'loss': 0.1059, 'grad_norm': 0.10621170699596405, 'learning_rate': 9.178875315329183e-07, 'epoch': 3.78}
{'loss': 0.1107, 'grad_norm': 0.10690198838710785, 'learning_rate': 6.100360177619946e-07, 'epoch': 3.82}
{'loss': 0.11, 'grad_norm': 0.08205580711364746, 'learning_rate': 3.6455629509730136e-07, 'epoch': 3.86}
{'loss': 0.115, 'grad_norm': 0.10496656596660614, 'learning_rate': 1.8175836599173546e-07, 'epoch': 3.9}
{'loss': 0.1058, 'grad_norm': 0.09522535651922226, 'learning_rate': 6.187307560754363e-08, 'epoch': 3.94}
{'loss': 0.1001, 'grad_norm': 0.11084733158349991, 'learning_rate': 5.051820295032261e-09, 'epoch': 3.98}
{'train_runtime': 17444.1924, 'train_samples_per_second': 1.806, 'train_steps_per_second': 0.028, 'train_loss': 0.030754005824162708, 'epoch': 4.0}
Finetuning finished.
wandb: - 4890.769 MB of 4890.769 MB uploaded (13.219 MB deduped)wandb: \ 4890.769 MB of 4890.769 MB uploaded (13.219 MB deduped)wandb: | 4890.769 MB of 4890.769 MB uploaded (13.219 MB deduped)wandb: / 4890.769 MB of 4890.769 MB uploaded (13.219 MB deduped)wandb: - 4890.769 MB of 4890.769 MB uploaded (13.219 MB deduped)wandb: \ 4890.793 MB of 4890.793 MB uploaded (13.219 MB deduped)wandb: | 4890.793 MB of 4890.793 MB uploaded (13.219 MB deduped)wandb: 
wandb: Run history:
wandb:               eval/loss â–ˆâ–
wandb:            eval/runtime â–ˆâ–
wandb: eval/samples_per_second â–â–
wandb:   eval/steps_per_second â–â–
wandb:             train/epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:       train/global_step â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:         train/grad_norm â–‡â–„â–‚â–†â–„â–†â–„â–…â–‚â–‚â–†â–‚â–…â–„â–†â–‚â–ƒâ–…â–„â–ƒâ–ˆâ–„â–…â–…â–â–…â–ƒâ–…
wandb:     train/learning_rate â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:              train/loss â–ƒâ–„â–„â–†â–„â–‚â–‡â–ˆâ–„â–â–„â–„â–‡â–ƒâ–„â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–ƒâ–„â–…â–…â–‡â–„â–‚
wandb: 
wandb: Run summary:
wandb:                eval/loss 0.1425
wandb:             eval/runtime 575.2181
wandb:  eval/samples_per_second 1.738
wandb:    eval/steps_per_second 0.217
wandb:               total_flos 3.138580840489943e+18
wandb:              train/epoch 3.99797
wandb:        train/global_step 492
wandb:          train/grad_norm 0.11085
wandb:      train/learning_rate 0.0
wandb:               train/loss 0.1001
wandb:               train_loss 0.03075
wandb:            train_runtime 17444.1924
wandb: train_samples_per_second 1.806
wandb:   train_steps_per_second 0.028
wandb: 
wandb: ðŸš€ View run deepseek_prover_base_no_err-by_file-09-07-08-59 at: https://wandb.ai/tcwong/decoder/runs/xjbmhng9
wandb: â­ï¸ View project at: https://wandb.ai/tcwong/decoder
wandb: Synced 5 W&B file(s), 0 media file(s), 33 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240907_212339-xjbmhng9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
